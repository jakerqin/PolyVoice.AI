"""
è¯Šæ–­æ™ºèƒ½ä½“ç³»ç»Ÿ

ä½¿ç”¨AutoGenæ„å»ºçš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œè´Ÿè´£æå–è¯Šæ–­å†…å®¹å¹¶è°ƒç”¨æµè§ˆå™¨æ™ºèƒ½ä½“
"""
import traceback
from app.logger import logger
from app.prompt.diagnosis import DIAGNOSIS_SYSTEM_PROMPT
from app.prompt.diagnosis_extract import DIAGNOSIS_EXTRACT_SYSTEM_PROMPT
from autogen import AssistantAgent, GroupChat, GroupChatManager
from app.config import config

from .browser_agent import BrowserAgent

class ContentExtractorAgent(AssistantAgent):
    """
    è‡ªå®šä¹‰å†…å®¹æå–æ™ºèƒ½ä½“ï¼Œå¯ä»¥å°†LLMçš„å“åº”å‘é€åˆ°å‰ç«¯
    """
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # æ·»åŠ å›è°ƒå‡½æ•°å±æ€§ï¼Œç”¨äºå‘å¤–éƒ¨ä¼ é€’æ¶ˆæ¯
        self.message_callback = None
    
    def set_message_callback(self, callback):
        """è®¾ç½®æ¶ˆæ¯å›è°ƒå‡½æ•°ï¼Œç”¨äºå°†LLMå“åº”ä¼ é€’ç»™å¤–éƒ¨å¤„ç†"""
        self.message_callback = callback
    
    def _generate_reply(self, messages=None, sender=None, config=None):
        """
        é‡å†™_generate_replyæ–¹æ³•ä»¥æ•è·LLMå“åº”
        æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨åŒæ­¥æ–¹æ³•ï¼Œä¸æ˜¯å¼‚æ­¥æ–¹æ³•
        """
        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•è·å–LLMå“åº”
        reply = super()._generate_reply(messages, sender, config)
        
        if reply and self.message_callback:
            # è®°å½•æ—¥å¿—
            log_message = f"ğŸ’¬ ContentExtractorå“åº”: {reply}"
            logger.info(log_message)
            
            # é€šè¿‡å›è°ƒå‡½æ•°å‘é€åˆ°å‰ç«¯
            self.message_callback(log_message)
        
        return reply

class DiagnosisAgents:
    """
    è¯Šæ–­æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä½¿ç”¨AutoGenæ¡†æ¶æ„å»º
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–è¯Šæ–­æ™ºèƒ½ä½“ç³»ç»Ÿ
        
        """
        # é…ç½®LLMï¼Œè¿™é‡Œä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥
        self.llm_config = {
            "config_list": [{
                "model": config.default_llm.model,
                "api_key": config.default_llm.api_key,
                "base_url": config.default_llm.base_url,
                "api_type": config.default_llm.api_type or "openai",
                "max_tokens": config.default_llm.max_tokens or 4096,
            }],
            "temperature": config.default_llm.temperature or 0.7
        }

        # åˆ›å»ºå†…å®¹æå–æ™ºèƒ½ä½“ï¼Œä½¿ç”¨è‡ªå®šä¹‰çš„ContentExtractorAgent
        self.contentExtractor = ContentExtractorAgent(
            name="ContentExtractor",
            system_message=DIAGNOSIS_SYSTEM_PROMPT,
            llm_config=self.llm_config,
        )
        self.browserAgent = BrowserAgent()
        
        # å­˜å‚¨è¦å‘é€åˆ°å‰ç«¯çš„æ¶ˆæ¯
        self.frontend_messages = []
    
    async def analyze_content(self, diagnosis_content: str, diagnosis_type: str):
        """
        åˆ†æè¯Šæ–­å†…å®¹å¹¶æœç´¢ç›¸å…³èµ„æº
        
        Args:
            diagnosis_content: è¯Šæ–­å†…å®¹
            diagnosis_type: è¯Šæ–­ç±»å‹ï¼ˆpronunciation, grammar, etcï¼‰
            
        Yields:
            å¤„ç†çŠ¶æ€å’Œç»“æœ
        """
        # è®°å½•å¼€å§‹å¤„ç†
        log_message = f"ğŸš€ å¼€å§‹å¤„ç†{diagnosis_type}è¯Šæ–­å†…å®¹"
        logger.info(log_message)
        
        yield {"type": "log", "data": log_message}
        
        # æ¸…ç©ºä¹‹å‰çš„æ¶ˆæ¯
        self.frontend_messages = []
        
        # è®¾ç½®å›è°ƒå‡½æ•°ï¼Œç”¨äºæ”¶é›†LLMå›å¤
        def collect_message(message):
            """æ™®é€šå‡½æ•°ï¼Œå°†æ¶ˆæ¯æ·»åŠ åˆ°åˆ—è¡¨ä¸­"""
            self.frontend_messages.append({"type": "log", "data": message})
            
        # å°†å›è°ƒå‡½æ•°è®¾ç½®åˆ°ContentExtractor
        self.contentExtractor.set_message_callback(collect_message)
        self.browserAgent.set_message_callback(collect_message)
        
        try:
            extractor_prompt = DIAGNOSIS_EXTRACT_SYSTEM_PROMPT.format(diagnosis_type=diagnosis_type, diagnosis_content=diagnosis_content)
            
            groupchat = GroupChat(
                agents=[
                    self.contentExtractor,
                    self.browserAgent
                ],
                messages=[],
                max_round=2,
                speaker_selection_method="round_robin"  # ä½¿ç”¨è½®æµå‘è¨€æ¨¡å¼ï¼Œç¡®ä¿æ¯ä¸ªæ™ºèƒ½ä½“éƒ½æœ‰æœºä¼šå‘è¨€
            )
            manager = GroupChatManager(
                groupchat=groupchat,
                llm_config=self.llm_config
            )
            
            # å¯åŠ¨å¯¹è¯ - æ³¨æ„è¿™é‡Œè¦åŒæ­¥è°ƒç”¨ï¼Œä¸éœ€è¦await
            manager.initiate_chat(
                recipient=self.contentExtractor,  # å‘é€ç»™å†…å®¹æå–æ™ºèƒ½ä½“
                message=extractor_prompt
            )
            
            # å°†æ”¶é›†åˆ°çš„æ¶ˆæ¯å‘é€åˆ°å‰ç«¯
            for message in self.frontend_messages:
                yield message
            
            # å®Œæˆå¤„ç†
            yield {"type": "complete", "data": "è¯Šæ–­åˆ†æå®Œæˆ"}
            
        except Exception as e:
            error_message = f"âŒ å¤„ç†è¯Šæ–­å†…å®¹å¤±è´¥: {str(e)}"
            logger.error(error_message)
            logger.error(f"è°ƒç”¨æ ˆä¿¡æ¯:\n{traceback.format_exc()}")
            yield {"type": "error", "data": error_message}
    

agents = DiagnosisAgents()

async def start_diagnosis_session(diagnosis_content: str, diagnosis_type: str):
    """
    å¯åŠ¨è¯Šæ–­ä¼šè¯
    
    Args:
        diagnosis_content: è¯Šæ–­å†…å®¹
        diagnosis_type: è¯Šæ–­ç±»å‹ï¼ˆpronunciation, grammar, etcï¼‰
        
    Yields:
        å¤„ç†çŠ¶æ€å’Œç»“æœ
    """
    async for result in agents.analyze_content(diagnosis_content, diagnosis_type):
        yield result
