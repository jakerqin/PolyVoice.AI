"""
è¯Šæ–­æ™ºèƒ½ä½“ç³»ç»Ÿ

ä½¿ç”¨AutoGenæ„å»ºçš„å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿï¼Œè´Ÿè´£æå–è¯Šæ–­å†…å®¹å¹¶è°ƒç”¨æµè§ˆå™¨æ™ºèƒ½ä½“
"""

import json
from app.logger import logger
from app.prompt.diagnosis import DIAGNOSIS_SYSTEM_PROMPT
from app.prompt.browser import BROWSER_SYSTEM_PROMPT
from app.prompt.diagnosis_extract import DIAGNOSIS_EXTRACT_SYSTEM_PROMPT
from autogen import AssistantAgent, UserProxyAgent
from app.config import config

from .browser_agent import BrowserAgent

class DiagnosisAgents:
    """
    è¯Šæ–­æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä½¿ç”¨AutoGenæ¡†æ¶æ„å»º
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–è¯Šæ–­æ™ºèƒ½ä½“ç³»ç»Ÿ
        
        """
        self.browser_agent = BrowserAgent()
        
        # é…ç½®LLMï¼Œè¿™é‡Œä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­çš„APIå¯†é’¥
        self.llm_config = {
            "config_list": [{
                "model": config.default_llm.model,
                "api_key": config.default_llm.api_key,
                "base_url": config.default_llm.base_url,
                "api_type": config.default_llm.api_type or "",
                "max_tokens": config.default_llm.max_tokens or 4096
            }],
            "temperature": config.default_llm.temperature or 0.7
        }
        
        # åˆ›å»ºå†…å®¹æå–æ™ºèƒ½ä½“
        self.content_extractor = AssistantAgent(
            name="ContentExtractor",
            system_message=DIAGNOSIS_SYSTEM_PROMPT,
            llm_config=self.llm_config,
        )
        
    
    async def analyze_content(self, diagnosis_content: str, diagnosis_type: str):
        """
        åˆ†æè¯Šæ–­å†…å®¹å¹¶æœç´¢ç›¸å…³èµ„æº
        
        Args:
            diagnosis_content: è¯Šæ–­å†…å®¹
            diagnosis_type: è¯Šæ–­ç±»å‹ï¼ˆpronunciation, grammar, etcï¼‰
            
        Yields:
            å¤„ç†çŠ¶æ€å’Œç»“æœ
        """
        # è®°å½•å¼€å§‹å¤„ç†
        log_message = f"ğŸš€ å¼€å§‹å¤„ç†{diagnosis_type}è¯Šæ–­å†…å®¹"
        logger.info(log_message)
        
        yield {"type": "log", "data": log_message}
        
        try:
            # åˆ›å»ºä¸€ä¸ªä»»åŠ¡ï¼Œè®©å†…å®¹æå–æ™ºèƒ½ä½“åˆ†æè¯Šæ–­å†…å®¹
            extractor_prompt = DIAGNOSIS_EXTRACT_SYSTEM_PROMPT.format(diagnosis_type=diagnosis_type, diagnosis_content=diagnosis_content)
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç”¨æˆ·ä»£ç†æ¥æ¥æ”¶å›å¤ï¼Œä¸å¯åŠ¨å®Œæ•´çš„å¯¹è¯
            temp_user = UserProxyAgent(
                name="TempUser",
                human_input_mode="NEVER",
                code_execution_config=False
            )
            
            # è®©ContentExtractorå›å¤ä¸€æ¬¡æ¶ˆæ¯
            await self.content_extractor.a_initiate_chat(
                temp_user,
                message=extractor_prompt
            )
            
            # ä»å†…å®¹æå–æ™ºèƒ½ä½“çš„æœ€åä¸€æ¡æ¶ˆæ¯ä¸­è·å–å†…å®¹
            messages = self.content_extractor.chat_messages[temp_user]
            if messages and len(messages) > 0:
                result_content = messages[-1]["content"]
            else:
                raise Exception("æœªèƒ½è·å–åˆ°å†…å®¹æå–æ™ºèƒ½ä½“çš„å“åº”")
            
            # å°è¯•ä»æ¶ˆæ¯ä¸­æå–JSON
            try:
                # æŸ¥æ‰¾æ¶ˆæ¯ä¸­çš„JSONéƒ¨åˆ†
                json_start = result_content.find("{")
                json_end = result_content.rfind("}") + 1
                
                if json_start >= 0 and json_end > json_start:
                    json_str = result_content[json_start:json_end]
                    extracted_data = json.loads(json_str)
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œåˆ™æ‰‹åŠ¨æ„å»º
                    extracted_data = {
                        "key_issues": [diagnosis_type + " issues"],
                        "search_keywords": [diagnosis_content.split()[:3]],
                        "summary": diagnosis_content[:100]
                    }
            except Exception as e:
                logger.error(f"è§£æJSONå¤±è´¥: {str(e)}")
                # æ„å»ºä¸€ä¸ªé»˜è®¤çš„æå–ç»“æœ
                extracted_data = {
                    "key_issues": [diagnosis_type + " problems"],
                    "search_keywords": [w for w in diagnosis_content.split()[:5] if len(w) > 3],
                    "summary": diagnosis_content[:100]
                }
            
            # è¿”å›æå–çš„æ•°æ®
            log_message = f"extract_agent: ğŸ“‘ æå–äº†å…³é”®å†…å®¹: {extracted_data}"
            yield {
                "type": "log", 
                "data": f"ğŸ“‘ æå–äº†å…³é”®å†…å®¹: {', '.join(extracted_data.get('search_keywords', []))}",
            }
            
            # ä½¿ç”¨æå–çš„å…³é”®è¯è°ƒç”¨æµè§ˆå™¨æ™ºèƒ½ä½“
            search_keywords = extracted_data.get("search_keywords", [])
            if not search_keywords:
                search_keywords = [w for w in diagnosis_content.split()[:5] if len(w) > 3]
            
            # æ‰§è¡Œæœç´¢
            async for result in self.browser_agent.search_content(search_keywords, diagnosis_type):
                yield result
                
        except Exception as e:
            error_message = f"âŒ å¤„ç†è¯Šæ–­å†…å®¹å¤±è´¥: {str(e)}"
            logger.error(error_message)
            
            yield {"type": "error", "data": error_message}
    
    async def close(self):
        """æ¸…ç†èµ„æº"""
        await self.browser_agent.close()


async def start_diagnosis_session(diagnosis_content: str, diagnosis_type: str):
    """
    å¯åŠ¨è¯Šæ–­ä¼šè¯
    
    Args:
        diagnosis_content: è¯Šæ–­å†…å®¹
        diagnosis_type: è¯Šæ–­ç±»å‹ï¼ˆpronunciation, grammar, etcï¼‰
        
    Yields:
        å¤„ç†çŠ¶æ€å’Œç»“æœ
    """
    agents = DiagnosisAgents()
    
    async for result in agents.analyze_content(diagnosis_content, diagnosis_type):
        yield result
